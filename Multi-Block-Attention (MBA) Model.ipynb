{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsv6_OqWA2eA"
      },
      "source": [
        "# Import package and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3I6kro3lWSJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f5042e-627e-412a-ce6f-b7c02b42a368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mat73\n",
            "  Downloading mat73-0.65-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from mat73) (3.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mat73) (2.0.2)\n",
            "Downloading mat73-0.65-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: mat73\n",
            "Successfully installed mat73-0.65\n"
          ]
        }
      ],
      "source": [
        "!pip install mat73\n",
        "import mat73\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import sys\n",
        "import random\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy.linalg as LA\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from scipy.interpolate import Rbf\n",
        "from scipy import interpolate\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import scipy.io as sio\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBaRE7dyit0r"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThRdecDCtDFh"
      },
      "outputs": [],
      "source": [
        "# !gdown 17FfAoAsvEhTFaQXB97xoVVKN4rDeBE41\n",
        "# !gdown 1b4Z_ngrkzTxZ1U1bWqCfE9gERvRZCYqq\n",
        "\n",
        "# !unzip '/content/Train_144.mat.zip'\n",
        "# !unzip '/content/Test_144.mat.zip'\n",
        "# !mkdir 'test'\n",
        "# !mkdir 'train'\n",
        "# !mv '/content/Test_144.mat' '/content/test/Test_144.mat'\n",
        "# !mv '/content/Train_144.mat' '/content/train/Train_144.mat'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################## CDL- Custom 16*144 ##############################\n",
        "!gdown 1TNjUt9JA5dRZRvnxu2a8FlzQEvnivpTd\n",
        "!gdown 1JLbwZk4QvM0c1MiDaHY6wztqKjslsP02\n",
        "\n",
        "!mkdir 'test'\n",
        "!mkdir 'train'\n",
        "\n",
        "!mv '/content/Test144.mat' '/content/test/Test144.mat'\n",
        "!mv '/content/Train144.mat' '/content/train/Train144.mat'"
      ],
      "metadata": {
        "id": "mxosgmftMoox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208b069c-cf25-4a8a-a158-2f898b1d1612"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1TNjUt9JA5dRZRvnxu2a8FlzQEvnivpTd\n",
            "From (redirected): https://drive.google.com/uc?id=1TNjUt9JA5dRZRvnxu2a8FlzQEvnivpTd&confirm=t&uuid=62b14b53-bc48-4bab-9df3-77e29cd363a9\n",
            "To: /content/Train144.mat\n",
            "100% 1.42G/1.42G [00:20<00:00, 68.7MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JLbwZk4QvM0c1MiDaHY6wztqKjslsP02\n",
            "From (redirected): https://drive.google.com/uc?id=1JLbwZk4QvM0c1MiDaHY6wztqKjslsP02&confirm=t&uuid=a763070a-b452-4150-a3c3-acc9bd5f62dd\n",
            "To: /content/Test144.mat\n",
            "100% 355M/355M [00:04<00:00, 83.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuVTrAyxtFXW"
      },
      "source": [
        "# LS Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YLtAnVlkC93N"
      },
      "outputs": [],
      "source": [
        "# DFT matrix\n",
        "def DFT_matrix(N):\n",
        "    m, n = np.meshgrid(np.arange(N), np.arange(N))\n",
        "    omega = np.exp( - 2 * np.pi * 1j / N )\n",
        "    D = np.power( omega, m * n )\n",
        "    return D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6OQT6jlAow2"
      },
      "source": [
        "## Some parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW-cMVViDMVF",
        "outputId": "15bcaace-0120-44d5-920d-be072f670fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144\n",
            "144\n"
          ]
        }
      ],
      "source": [
        "M_t = 144\n",
        "Nt = 16\n",
        "M = 144\n",
        "ch = 2\n",
        "\n",
        "snr = 20\n",
        "SNR=10.0**(snr/10.0) # transmit power\n",
        "\n",
        "# linear_spaced_array = np.linspace(0, M, M_t+1)\n",
        "# IRS_index = np.round(linear_spaced_array).astype(int)\n",
        "# print(IRS_index[:-1])\n",
        "IRS_index = range(0,M,1)\n",
        "\n",
        "PHI = np.zeros((M,M_t), dtype=complex)\n",
        "PHI_t = DFT_matrix(len(IRS_index))\n",
        "\n",
        "for c in range(M_t):\n",
        "  index = IRS_index[c]\n",
        "  for i in range(M_t):\n",
        "    PHI[index,i]=PHI_t[c,i]\n",
        "print(M_t)\n",
        "print(len(IRS_index))\n",
        "\n",
        "phi = np.dot(PHI,np.transpose(np.conjugate(PHI)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaBVQxY7ArUy"
      },
      "source": [
        "## Preprocessing on Train datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeuVSUb1C4Up",
        "outputId": "7de11158-fa5d-455b-a2e4-aa72a7478fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.58120506114146\n",
            "19.981773774951492\n",
            "(2000, 16, 144, 2) (2000, 16, 144, 2)\n"
          ]
        }
      ],
      "source": [
        "############## training set generation ##################\n",
        "file_dir = '/content/train'\n",
        "\n",
        "data_num_train = 2000\n",
        "data_num_file = 2000\n",
        "Y=np.zeros((Nt,M_t), dtype=float)\n",
        "H_train=np.zeros((data_num_train,Nt,M,ch), dtype=float)\n",
        "H_train_noisy=np.zeros((data_num_train,Nt,M,ch), dtype=float)\n",
        "filedir = os.listdir(file_dir)  # type the path of training data\n",
        "\n",
        "SNRr = 0\n",
        "\n",
        "for filename in filedir:\n",
        "    newname = os.path.join(file_dir, filename)\n",
        "    data = mat73.loadmat(newname)\n",
        "    channel = data['H']\n",
        "    data = []\n",
        "    for i in range(data_num_file):\n",
        "        # H = np.sqrt(2304/74)*channel[:,:,i]\n",
        "        # H = np.sqrt(4.5232e+08)*channel[:,:,i]\n",
        "        H = np.sqrt(143.4916)*channel[:,:,i]\n",
        "        H_re = np.real(H)\n",
        "        H_im = np.imag(H)\n",
        "\n",
        "        H_train[i, :, :, 0] = H_re\n",
        "        H_train[i, :, :, 1] = H_im\n",
        "\n",
        "        N = np.random.normal(0, 1 / np.sqrt(2), size=(Nt, M)) + 1j * np.random.normal(0, 1 / np.sqrt(2), size=(Nt, M))\n",
        "        N_hat = np.dot(N,phi)\n",
        "\n",
        "        H_hat = np.dot(H,phi)\n",
        "        Y = H_hat + (1.0/SNR) * N_hat\n",
        "        H_hat_re = np.real(Y)\n",
        "        H_hat_im = np.imag(Y)\n",
        "\n",
        "        SNRr = SNRr + SNR * (LA.norm(H_hat)) ** 2 / (LA.norm(N_hat)) ** 2\n",
        "\n",
        "        H_train_noisy[i, :, :, 0] = H_hat_re\n",
        "        H_train_noisy[i, :, :, 1] = H_hat_im\n",
        "\n",
        "print(SNRr/(data_num_train))\n",
        "SNRR = 10 * np.log10(SNRr/(data_num_train))\n",
        "print(SNRR)\n",
        "print(H_train.shape,H_train_noisy.shape)\n",
        "channel = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z0X-iO_AwAJ"
      },
      "source": [
        "## Preprocessing on test datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-dIUeAORyB5",
        "outputId": "d319243e-3154-4fbd-e802-c3f951f070a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.85376893723786\n",
            "19.993644617731107\n",
            "(500, 16, 144, 2) (500, 16, 144, 2)\n"
          ]
        }
      ],
      "source": [
        "############## training set generation ##################\n",
        "file_dir_test = '/content/test'\n",
        "\n",
        "data_num_test = 500\n",
        "data_num_file = 500\n",
        "Y=np.zeros((Nt,M), dtype=float)\n",
        "H_test=np.zeros((data_num_test,Nt,M,ch), dtype=float)\n",
        "H_test_noisy=np.zeros((data_num_test,Nt,M,ch), dtype=float)\n",
        "filedir = os.listdir(file_dir_test)  # type the path of training data\n",
        "\n",
        "SNRr = 0\n",
        "\n",
        "for filename in filedir:\n",
        "    newname = os.path.join(file_dir_test, filename)\n",
        "    data = mat73.loadmat(newname)\n",
        "    # data = sio.loadmat(newname)\n",
        "    channel = data['H']\n",
        "    for i in range(data_num_test):\n",
        "        # H = np.sqrt(2304/74)*channel[:,:,i]\n",
        "        # H = np.sqrt(4.5232e+08)*channel[:,:,i]\n",
        "        H = np.sqrt(144.0692)*channel[:,:,i]\n",
        "\n",
        "        H_re = np.real(H)\n",
        "        H_im = np.imag(H)\n",
        "\n",
        "        H_test[i, :, :, 0] = H_re\n",
        "        H_test[i, :, :, 1] = H_im\n",
        "\n",
        "        N = np.random.normal(0, 1 / np.sqrt(2), size=(Nt, M)) + 1j * np.random.normal(0, 1 / np.sqrt(2), size=(Nt, M))\n",
        "\n",
        "        N_hat = np.dot(N,phi)\n",
        "        H_hat = np.dot(H,phi)\n",
        "\n",
        "        Y = H_hat + (1.0/SNR) * N_hat\n",
        "        H_hat_re = np.real(Y)\n",
        "        H_hat_im = np.imag(Y)\n",
        "\n",
        "        SNRr = SNRr + SNR * (LA.norm(H_hat)) ** 2 / (LA.norm(N_hat)) ** 2\n",
        "\n",
        "        H_test_noisy[i, :, : ,0] = H_hat_re\n",
        "        H_test_noisy[i, :, :, 1] = H_hat_im\n",
        "\n",
        "print(SNRr/(data_num_test))\n",
        "SNRR = 10 * np.log10(SNRr/(data_num_test))\n",
        "print(SNRR)\n",
        "print(H_test.shape,H_test_noisy.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIhaPzPlWnKM"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9A88laDXYn7K"
      },
      "outputs": [],
      "source": [
        "class mydataset(Dataset):\n",
        "  def __init__(self , datas , labels):\n",
        "    super(mydataset,self).__init__()\n",
        "    self.datas = torch.tensor(datas , dtype=torch.float)\n",
        "    self.datas = torch.permute(self.datas, (0,3,1,2)) # must to use torch.permute beacuse the channel must be after batch size [batch_size , channel , nr , nt]\n",
        "\n",
        "    self.labels = torch.tensor(labels , dtype=torch.float)\n",
        "    self.labels = torch.permute(self.labels, (0,3,1,2)) #  must to use torch.permute beacuse the channel must be after batch size [batch_size , channel , nr , nt]\n",
        "  def __getitem__(self, index):\n",
        "    return self.datas[index] , self.labels[index]\n",
        "  def __len__(self):\n",
        "    return self.datas.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O79mUFs1Ypvj"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "batch_test = 64\n",
        "\n",
        "trainset = mydataset(H_train_noisy , H_train)\n",
        "trainloader = DataLoader(trainset , batch_size = batch_size , shuffle = True, drop_last=True)\n",
        "\n",
        "testset = mydataset(H_test_noisy , H_test)\n",
        "testloader = DataLoader(testset , batch_size = batch_test , shuffle = False, drop_last=True)\n",
        "\n",
        "def test_DnCNN(testloader,model):\n",
        "  nmse = np.zeros((1000,1))\n",
        "  k = 0\n",
        "  model.eval()\n",
        "  for (input,label) in tqdm(testloader):\n",
        "    nmse2=torch.zeros((batch_test,1), dtype=torch.float16)\n",
        "\n",
        "    input,label = input.to(device),label.to(device)\n",
        "    decoded_channel = model(input)\n",
        "\n",
        "    for n in range(batch_test):\n",
        "        MSE=((label[n,:,:,:]-decoded_channel[n,:,:,:])**2).sum()\n",
        "        norm_real=((label[n,:,:,:])**2).sum()\n",
        "        nmse2[n]=MSE/norm_real\n",
        "\n",
        "    a = nmse2.sum()\n",
        "    nmse[k] = a.detach().numpy()\n",
        "    k = k + 1\n",
        "\n",
        "  return nmse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oSoh3930oNeb"
      },
      "outputs": [],
      "source": [
        "def test_SrCNN(testloader,model):\n",
        "  nmse = np.zeros((1000,1))\n",
        "  k = 0\n",
        "  dn_model.eval()\n",
        "  model.eval()\n",
        "  for (input,label) in tqdm(testloader):\n",
        "    nmse2=torch.zeros((batch_test,1), dtype=torch.float16)\n",
        "\n",
        "    input,label = input.to(device),label.to(device)\n",
        "    input2 = dn_model(input)\n",
        "    decoded_channel = model(input2)\n",
        "\n",
        "    for n in range(batch_test):\n",
        "        MSE=((label[n,:,:,:]-decoded_channel[n,:,:,:])**2).sum()\n",
        "        norm_real=((label[n,:,:,:])**2).sum()\n",
        "        nmse2[n]=MSE/norm_real\n",
        "\n",
        "    a = nmse2.sum()\n",
        "    nmse[k] = a.detach().numpy()\n",
        "    k = k + 1\n",
        "\n",
        "  return nmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_0LZRb2Se4qh"
      },
      "outputs": [],
      "source": [
        "H_train_noisy =[]\n",
        "H_train = []\n",
        "H_test_noisy =[]\n",
        "H_test = []\n",
        "data = []\n",
        "channel = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFXAfLwoXFEi"
      },
      "source": [
        "# **Convolutional Attention Network (CAN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuig2LN8_6z0"
      },
      "source": [
        "## MBconv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jKZ_Kwjfodtg"
      },
      "outputs": [],
      "source": [
        "class MBconv1(nn.Module):\n",
        "    def __init__(self,channel):\n",
        "      super(MBconv1, self).__init__()\n",
        "      self.channel = channel\n",
        "      self.Conv2dNormActivation1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels= channel*2, out_channels= channel*2, kernel_size=3 , stride=1 , padding=1 , groups=channel*2),\n",
        "          nn.BatchNorm2d(channel*2),\n",
        "          nn.SiLU()\n",
        "      )\n",
        "      self.SqueezeExcitation = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = channel*2 , out_channels = channel//2 , kernel_size= 1, stride= 1),\n",
        "          nn.Conv2d(in_channels = channel//2 , out_channels = channel*2 , kernel_size=1 , stride= 1),\n",
        "          nn.SiLU(),\n",
        "      )\n",
        "      self.Conv2dNormActivation2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=channel*2 , out_channels=channel , kernel_size=1 , stride=1 ,padding=1),\n",
        "          nn.BatchNorm2d(channel ,eps=0.001 , momentum=0.01),\n",
        "      )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = self.Conv2dNormActivation1(x)\n",
        "      x1 = x1+x\n",
        "      x2 = self.SqueezeExcitation(x1)\n",
        "      x2 = x2+x1\n",
        "      x3 = self.Conv2dNormActivation2(x2)\n",
        "      return x3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NnPtrMBARsZ"
      },
      "source": [
        "## Attention block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kKyDWRqPARPC"
      },
      "outputs": [],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super(AttentionBlock, self).__init__()\n",
        "    self.conv_query = MBconv1(16)\n",
        "    self.conv_key = MBconv1(16)\n",
        "    self.conv_value = MBconv1(16)\n",
        "    self.conv_out = nn.Conv2d(16, 32, kernel_size=3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    query = self.conv_query(x)\n",
        "    key = self.conv_key(x)\n",
        "    value = self.conv_value(x)\n",
        "\n",
        "    # Apply channel scaling for stability\n",
        "    d_k = query.size(1)\n",
        "    attention = F.softmax(torch.einsum('bchw, bkhw -> bchw', query, key) / d_k, dim=1)\n",
        "    context = torch.einsum('bchw, bchw -> bchw', attention, value)\n",
        "    out = self.conv_out(context)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cRE0g1tAUTY"
      },
      "source": [
        "## MB-Attention model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SrtkFu9bilBI"
      },
      "outputs": [],
      "source": [
        "class DenoisingNetwork(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super(DenoisingNetwork, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=2, padding=1)\n",
        "    self.attn1 = AttentionBlock(32)\n",
        "    self.conv2 = nn.Conv2d(32, 32, kernel_size=2)\n",
        "    self.attn2 = AttentionBlock(32)\n",
        "    self.conv3 = nn.Conv2d(32, in_channels, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.conv1(x)\n",
        "    x1 = F.relu(x1)\n",
        "    x2 = self.attn1(x1)\n",
        "    x2 = x1+x2\n",
        "\n",
        "    x2 = F.relu(self.conv2(x2))\n",
        "\n",
        "    x3 = self.attn2(x2)\n",
        "    x3 = x3+x2\n",
        "    # x3 = F.relu(x3)\n",
        "\n",
        "    x3 = self.conv3(x3)\n",
        "    # x3 = self.dnCnn(x3)\n",
        "    return x - x3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EV24iuhY4Bi",
        "outputId": "39e9c558-b1b9-46c8-ad50-90351e9b632d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2, 16, 144])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dn_model = DenoisingNetwork(2).to(device)\n",
        "x = torch.rand(64,2,Nt,M).to(device)\n",
        "dn_model(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5APkGOKqhv9",
        "outputId": "e7f54506-68c5-40cb-9759-f2ced1d201a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gen has 22,738 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The gen has {count_parameters(dn_model):,} trainable parameters')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqUxjoK86xKk"
      },
      "source": [
        "# Default setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mFqUtKz7CynK"
      },
      "outputs": [],
      "source": [
        "optimizer_dn = torch.optim.Adam(dn_model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n",
        "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer_dn, T_max=800)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer_dn , step_size = 100 , gamma=0.6)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "logger = logging.getLogger('MBA: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Bj19Kwm0YElm"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-48-toh560e1"
      },
      "source": [
        "# Training function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # # and it will lead to many hours of debugging \\:\n",
        "    # for param_group in optimizer.param_groups:\n",
        "    #     param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "jgKvaxfm64O-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TopB79FZXQv5"
      },
      "outputs": [],
      "source": [
        "train_loss=[]\n",
        "def train_network2(train_loader):\n",
        "  total_loss = AverageMeter()\n",
        "  dn_model.train()\n",
        "  for (x, labels) in tqdm(train_loader): #for each batch calculate something for 1 epoch.\n",
        "    x, labels = x.to(device) , labels.to(device)\n",
        "    outputs = dn_model(x)\n",
        "    loss = criterion(outputs, labels) #loss between out and lables\n",
        "    optimizer_dn.zero_grad() #befor use next line better to use zero.grad( )\n",
        "    loss.backward()\n",
        "    optimizer_dn.step()\n",
        "    total_loss.update(loss)\n",
        "    # lr_scheduler.step()\n",
        "  train_loss.append(total_loss.avg.cpu().detach().numpy() )\n",
        "  # logger.info(f'Train: Epoch:{epoch} \\t Loss:{total_loss.avg:.4} ')\n",
        "  logger.info(f'Train: Epoch:{epoch} \\t Loss:{total_loss.avg:.4} \\t lr:{lr_scheduler.get_last_lr()}')\n",
        "  if epoch == end-1:\n",
        "    torch.save(dn_model,'MB_Attention.pth')\n",
        "    print('\\n Model saving ... \\n')\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXsDa1sXXeGU"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load_model= '/content/MBA_epoch_250.pth.tar'\n",
        "# load_checkpoint(load_model,dn_model,optimizer_dn,0.0002)"
      ],
      "metadata": {
        "id": "lsV57QJY7PVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jMewpNRWXddM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "96313c98-8cee-4b4d-ab2a-2d8adf480827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:02<00:00, 13.31it/s]\n",
            "INFO:MBA: :Train: Epoch:1 \t Loss:9.713e+03 \t lr:[0.0002]\n",
            "100%|██████████| 7/7 [00:00<00:00, 26.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMSE_test = inf\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:01<00:00, 17.54it/s]\n",
            "INFO:MBA: :Train: Epoch:2 \t Loss:6.931e+03 \t lr:[0.0002]\n",
            "100%|██████████| 7/7 [00:00<00:00, 31.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMSE_test = inf\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:01<00:00, 17.57it/s]\n",
            "INFO:MBA: :Train: Epoch:3 \t Loss:3.95e+03 \t lr:[0.0002]\n",
            "100%|██████████| 7/7 [00:00<00:00, 31.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMSE_test = inf\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:01<00:00, 17.49it/s]\n",
            "INFO:MBA: :Train: Epoch:4 \t Loss:1.56e+03 \t lr:[0.0002]\n",
            "100%|██████████| 7/7 [00:00<00:00, 31.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMSE_test = inf\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:01<00:00, 17.42it/s]\n",
            "INFO:MBA: :Train: Epoch:5 \t Loss:439.5 \t lr:[0.0002]\n",
            "100%|██████████| 7/7 [00:00<00:00, 28.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMSE_test = 374.656\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 28/31 [00:01<00:00, 16.60it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1717753472.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m211\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_network2\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mnmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_DnCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmse_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdata_num_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-356242766.py\u001b[0m in \u001b[0;36mtrain_network2\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#loss between out and lables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer_dn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#befor use next line better to use zero.grad( )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer_dn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "NMSE_test = []\n",
        "start , end = 1 , 211\n",
        "for epoch in range (start , end):\n",
        "  train_network2( trainloader )\n",
        "  nmse_test = test_DnCNN(testloader,dn_model)\n",
        "  c = nmse_test.sum()/data_num_test\n",
        "  NMSE_test.append(c)\n",
        "  print('NMSE_test = {}'.format(c))\n",
        "  lr_scheduler.step()\n",
        "  print('--------------------------------------------------------------')\n",
        "  if epoch >= 51 and epoch%5==0:\n",
        "    plt.plot(NMSE_test[50:-1])\n",
        "    plt.show()\n",
        "    print(np.min(NMSE_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "R2xu8UYuXjOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "aa3e692e-ea3a-49dc-8e50-ba2eb852314a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "374.656\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(np.min(NMSE_test))\n",
        "plt.plot(NMSE_test[1:-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9rvWbhoncID"
      },
      "source": [
        "# **Complex Multi-Convolutional Network (CMN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB6JiAd1_Yi3"
      },
      "source": [
        "## Conv Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GGmKTLj93Qk0"
      },
      "outputs": [],
      "source": [
        "class convblock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(convblock, self).__init__()\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "      x2 = self.conv2(x)\n",
        "      x2 = x2+x\n",
        "      return x2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAy8AK2z_bBc"
      },
      "source": [
        "## Res-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8bHaHJbqxwf9"
      },
      "outputs": [],
      "source": [
        "class SRblock(nn.Module):\n",
        "    def __init__(self, ch_in,num_blocks):\n",
        "        super(SRblock, self).__init__()\n",
        "        self.ch_in = ch_in\n",
        "        self.num_blocks = num_blocks\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=ch_in,out_channels=64,kernel_size=2),\n",
        "            nn.PReLU(),\n",
        "        )\n",
        "        blocks=[]\n",
        "        for i in range(num_blocks):\n",
        "            blocks.append(\n",
        "                convblock()\n",
        "                )\n",
        "        self.convBLOCK = nn.Sequential(*blocks)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.conv4 = nn.Conv2d(in_channels=64,out_channels=2,kernel_size=2,stride=1,padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = self.conv1(x)\n",
        "      # print(x1.shape)\n",
        "      x2 = self.convBLOCK(x1)\n",
        "      # print(x2.shape)\n",
        "      x3 = self.conv3(x2)\n",
        "      x3 = x3+x1\n",
        "      out = self.conv4(x3)\n",
        "      return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sOsQGhoiiyIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1956bb6b-8e67-4f30-d74f-26c353e2f4d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2, 16, 144])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "x = torch.rand(64,2,16,144).to(device)\n",
        "sr_model = SRblock(2,4).to(device)\n",
        "sr_model(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGw2gcK1_rMW"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7jnnTTQGntYf"
      },
      "outputs": [],
      "source": [
        "optimizer_sr = torch.optim.Adam(sr_model.parameters(),lr=0.0001, betas=(0.9, 0.999), eps=1e-8)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "y2ECg-0On3rn"
      },
      "outputs": [],
      "source": [
        "train_loss=[]\n",
        "def train_network(model, train_loader):\n",
        "  total_loss = AverageMeter()\n",
        "  model.train()\n",
        "  dn_model.eval()\n",
        "  for (x, labels) in tqdm(train_loader): #for each batch calculate something for 1 epoch.\n",
        "    x, labels = x.to(device) , labels.to(device)\n",
        "    out = dn_model(x)\n",
        "    outputs = model(out)\n",
        "    loss = criterion(outputs, labels) #loss between out and lables\n",
        "    optimizer_sr.zero_grad() #befor use next line better to use zero.grad( )\n",
        "    loss.backward()\n",
        "    optimizer_sr.step()\n",
        "    total_loss.update(loss)\n",
        "  train_loss.append(total_loss.avg.cpu().detach().numpy() )\n",
        "  logger.info(f'Train: Epoch:{epoch} \\t Loss:{total_loss.avg:.4}')\n",
        "  if epoch == end-1:\n",
        "   torch.save(sr_model,'SR_CNN.pth')\n",
        "   print('\\n \\t\\t\\t\\t\\t\\t\\t\\tModel saving ... \\n')\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjXLjyR-_wWT"
      },
      "source": [
        "# Training phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YuH9g7njolnx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "14472d35-ba40-4ec7-ba38-61c4af907aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:04<00:00,  6.82it/s]\n",
            "INFO:MBA: :Train: Epoch:1 \t Loss:1.508\n",
            "100%|██████████| 7/7 [00:00<00:00, 15.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMSE_test = 0.858125\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:04<00:00,  6.85it/s]\n",
            "INFO:MBA: :Train: Epoch:2 \t Loss:0.277\n",
            "100%|██████████| 7/7 [00:00<00:00, 12.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMSE_test = 0.3399375\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:04<00:00,  6.77it/s]\n",
            "INFO:MBA: :Train: Epoch:3 \t Loss:0.1407\n",
            "100%|██████████| 7/7 [00:00<00:00, 15.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMSE_test = 0.210421875\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 14/31 [00:02<00:02,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1665221448.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr_model\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mnmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_SrCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmse_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdata_num_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-767031719.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#for each batch calculate something for 1 epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "NMSE_test = []\n",
        "start , end = 1 , 401\n",
        "for epoch in range (start , end):\n",
        "  train_network(sr_model , trainloader )\n",
        "  nmse_test = test_SrCNN(testloader,sr_model)\n",
        "  c = nmse_test.sum()/data_num_test\n",
        "  NMSE_test.append(c)\n",
        "  print('NMSE_test = {}'.format(c))\n",
        "  print('--------------------------------------------------------------')\n",
        "  if epoch%5==0:\n",
        "    plt.plot(NMSE_test)\n",
        "    plt.show()\n",
        "    print(np.min(NMSE_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "boakhskzoxaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "43fffe03-5fe3-4b29-9223-b9771f919b2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.210421875)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "plt.plot(NMSE_test)\n",
        "plt.show()\n",
        "np.min(NMSE_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_test=(torch.permute(torch.tensor(H_test , dtype = torch.float32),(0,3,1,2))).to(device)\n",
        "H_test_noisy=torch.permute(torch.tensor(H_test_noisy,dtype = torch.float32),(0,3,1,2)).to(device)"
      ],
      "metadata": {
        "id": "bR4AePQmC01y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "db1566e6-f4e1-4db8-9eed-f6e460509f16"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 4",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2607578381.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mH_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mH_test_noisy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_test_noisy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_test_noisy.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "JeJ4-RCZmJrJ",
        "outputId": "ede2f0cd-a7ee-4b73-d876-28c662272aad"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1452026331.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mH_test_noisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# t1=time.time()\n",
        "# dn_model.eval()\n",
        "dn_model.eval()\n",
        "t1=time.time()\n",
        "decoded_channel = sr_model(H_test_noisy)\n",
        "t2=time.time()\n",
        "# decoded_channel = dn_model(H_test_interpolated)\n",
        "t2=time.time()\n",
        "# nmse2=torch.zeros((data_num_test,1), dtype=torch.float16)\n",
        "# for n in range(data_num_test):\n",
        "#     MSE=((H_train[n,:,:,:]-decoded_channel[n,:,:,:])**2).sum()\n",
        "#     norm_real=((H_train[n,:,:,:])**2).sum()\n",
        "#     nmse2[n]=MSE/norm_real\n",
        "# print('NMSE = ',nmse2.sum()/(data_num_test))  # calculate NMSE after training stage (testing performance)\n",
        "total_time = t2-t1\n",
        "total_time = total_time/(H_test_noisy.shape[0])\n",
        "print('t2-t1 = ',t2-t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "otJZMDjE_xEQ",
        "outputId": "b5fb7e08-2850-4ab5-fce9-dbdd2ef1e96c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "conv2d() received an invalid combination of arguments - got (list, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!list of []!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!list of []!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-157020389.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdecoded_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_test_noisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# decoded_channel = dn_model(H_test_interpolated)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2002830542.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;31m# print(x1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvBLOCK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (list, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!list of []!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!list of []!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_test=10\n",
        "testset = mydataset(H_test_noisy , H_test)\n",
        "testloader = DataLoader(testset , batch_size = batch_test , shuffle = False, drop_last=True)\n",
        "\n",
        "def test(testloader,model):\n",
        "  nmse=np.zeros((1000,1), dtype=float16)\n",
        "  k = 0\n",
        "  model.eval()\n",
        "  for (input,label) in tqdm(testloader):\n",
        "    nmse2=torch.zeros((batch_test,1), dtype=torch.float16)\n",
        "\n",
        "    input,label = input.to(device),label.to(device)\n",
        "    t1=time.time()\n",
        "    decoded_channel = dn_model(input)\n",
        "    t2=time.time()\n",
        "\n",
        "    for n in range(batch_test):\n",
        "        MSE=((label[n,:,:,:]-decoded_channel[n,:,:,:])**2).sum()\n",
        "        norm_real=((label[n,:,:,:])**2).sum()\n",
        "        nmse2[n]=MSE/norm_real\n",
        "\n",
        "    a = nmse2.sum()\n",
        "    nmse[k] = a.detach().numpy()\n",
        "    k = k + 1\n",
        "\n",
        "  return nmse"
      ],
      "metadata": {
        "id": "rs6Oqt25EbMg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AIhaPzPlWnKM",
        "JFXAfLwoXFEi",
        "NqUxjoK86xKk",
        "-48-toh560e1",
        "E9rvWbhoncID",
        "YB6JiAd1_Yi3",
        "oGw2gcK1_rMW"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}